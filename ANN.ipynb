{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0wQZcfKIZKfc5lYXFdL3r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Deciding whether to implement a traditional machine learning (ML) model or a deep learning model depends on various factors, and it's important to consider the following aspects when making your choice:\n","\n","Data Volume: Deep learning models typically require a large amount of data to perform well. If you have a small dataset, traditional ML models might be more appropriate because they can generalize better from limited data.\n","\n","Data Complexity: Deep learning models excel at handling complex data with many features or high-dimensional data, such as images, audio, and text. If your data has inherent hierarchical structures or complex patterns, deep learning might be suitable.\n","\n","Task Type: Consider the type of machine learning task you're dealing with. For simpler tasks like linear regression, classification, or clustering, traditional ML models are often sufficient. Deep learning models shine in tasks that involve natural language processing (NLP), computer vision, speech recognition, and other complex tasks.\n","\n","Interpretability: Traditional ML models are generally more interpretable. If understanding the decision process of the model is critical (e.g., in healthcare or finance), you may prefer traditional ML models.\n","\n","Training Time: Deep learning models tend to have longer training times, especially with large datasets and complex architectures. Traditional ML models typically train faster.\n","\n","Computational Resources: Deep learning models demand significant computational resources, including GPUs or TPUs. Make sure you have access to the required hardware.\n","\n","Model Complexity: Deep learning models can have a vast number of parameters and complex architectures. If a simpler model can provide a satisfactory solution, opt for traditional ML to reduce model complexity."],"metadata":{"id":"iYpw9mCSc-Xd"}},{"cell_type":"markdown","source":["# **ANN->Fully connected layer ->Feed forward network**\n","## ANN for classification"],"metadata":{"id":"KGHPXv3ovMih"}},{"cell_type":"markdown","source":["# **(1) Importing the libraries**"],"metadata":{"id":"Ha6jZr9BcYDh"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"ttnTXiCttfHa","executionInfo":{"status":"ok","timestamp":1698145653485,"user_tz":-330,"elapsed":858,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf #Importing tensorflow for deep learning\n","#Here at tf-2.0, Keras is integrated with it by default"]},{"cell_type":"code","source":["tf.__version__ #For checking the version of tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"DzVIubQRcrpB","executionInfo":{"status":"ok","timestamp":1698145653486,"user_tz":-330,"elapsed":13,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"1e9a0a75-dff3-456a-e2cd-7b7b8d3232ec"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.14.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# **(2) Data Preprocessing**"],"metadata":{"id":"aQlkHKrCdFdy"}},{"cell_type":"markdown","source":["## Importing Dataset and"],"metadata":{"id":"Eklv_jzBPLqV"}},{"cell_type":"code","source":["dataset=pd.read_csv(\"Churn_Modelling.csv\")\n","X=dataset.iloc[:,3:-1].values\n","Y=dataset.iloc[:,-1].values"],"metadata":{"id":"unD327JddOvS","executionInfo":{"status":"ok","timestamp":1698145653486,"user_tz":-330,"elapsed":10,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print(X[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_tvIgJQ9h91T","executionInfo":{"status":"ok","timestamp":1698145653487,"user_tz":-330,"elapsed":11,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"9632b72d-b56d-4db7-c340-468aef4dd0f8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[619 'France' 'Female' 42 2 0.0 1 1 1 101348.88]\n"]}]},{"cell_type":"markdown","source":["## No Missing Values, so going for Categorial Datas Encoding\n","###(1)Encoding the Gender, where order matters as male should a number and female represents a number, from simple labeling"],"metadata":{"id":"qeamWgMRf30e"}},{"cell_type":"code","source":["# Here order matters for gender, encode the female or male nothing much comlicated, only 0 and 1\n","from sklearn.preprocessing import LabelEncoder #For that using labelEncoder mainly for binaryType Encoding (Yes or No)\n","le=LabelEncoder()\n","X[:,2]=np.array(le.fit_transform(X[:,2]))# Dependent variable vector doesnot have to have numpy Array\n","print(X[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBmKrfTUicJo","executionInfo":{"status":"ok","timestamp":1698145655220,"user_tz":-330,"elapsed":1741,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"c754034a-8f4f-4c36-92a3-fd595861fa52"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[619 'France' 0 42 2 0.0 1 1 1 101348.88]\n"]}]},{"cell_type":"markdown","source":["###(2)Encoding the CountryName, where order doesnot matters, so going for HotEcoding (3-countries)"],"metadata":{"id":"-nEGgLl0SYi9"}},{"cell_type":"code","source":["#(1)Encoding the CountryName, where order doesnot matters, so going for HotEcoding (3-countries)\n","from sklearn.compose import ColumnTransformer # Used for tansforming into encodes\n","from sklearn.preprocessing import OneHotEncoder # Encoding type, That is HOtEncoding\n","ct= ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')\n","#For transformer: 1-Arg= Which kind of transformation that is Encoding\n","                 # 2-Arg= Which Encoding that HotEncoding\n","                 # 3-Arg which indexs want we to encode: col-index number\n","#For remainder=passthourgh: If not applied, then hot encoding done from 0 to secondlast col by default\n","\n","#Now lets connect the above object with the input-Matrix X:\n","#Unlike for missing value diferent steps for fitting and tranforming, here module has both in one\n","X=np.array(ct.fit_transform(X)) #ct.fit_trans donot returns the matrix into numpy array but X dataset should be numpyArray\n","print(X[0])#The resultant replacement by the dummyVaraibles, they move to first column"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nePFZzaVdboC","executionInfo":{"status":"ok","timestamp":1698145655221,"user_tz":-330,"elapsed":7,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"8d0910e8-32ab-4eb6-92c1-666bee037270"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.0 0.0 0.0 619 0 42 2 0.0 1 1 1 101348.88]\n"]}]},{"cell_type":"markdown","source":["## Splitting dataset"],"metadata":{"id":"9rLTR_CGWwfL"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,Y_train,Y_test=train_test_split(X,Y,random_state=0,test_size=0.3)"],"metadata":{"id":"VNwoFXXMWy9l","executionInfo":{"status":"ok","timestamp":1698145655221,"user_tz":-330,"elapsed":6,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["##Feature Scaling as here we are doing classification"],"metadata":{"id":"PKKDQhQ7XKLz"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","sc_x=StandardScaler()\n","X_train=sc_x.fit_transform(X_train)\n","X_test=sc_x.transform(X_test)"],"metadata":{"id":"usAsS-z2XMqF","executionInfo":{"status":"ok","timestamp":1698145655221,"user_tz":-330,"elapsed":5,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# **(3) Building ANN**"],"metadata":{"id":"QeX8vSm4XnOU"}},{"cell_type":"markdown","source":["## Initializing the ANN\n","### Here will be creating Variable which noting but a ANN-variable as an object of certain sequatiall-class, which allow to build ANN as sequence of layer"],"metadata":{"id":"vrmjBGD6YvHp"}},{"cell_type":"code","source":["ann=tf.keras.models.Sequential() #Class from models module from Keras library integrated with tf\n","#Initilases the ann-variable as sequence of layers, ann object of Sequntial Class"],"metadata":{"id":"ZxaiI9v3X5l-","executionInfo":{"status":"ok","timestamp":1698145655221,"user_tz":-330,"elapsed":5,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Adding the input layer and first hidden layer"],"metadata":{"id":"11mxkshjahyd"}},{"cell_type":"code","source":["#Right now we have to add fully connected Layer(ANN) will be build as an object of DenseClass\n","#From the instance of the Sequantial-Class, ann object has add method for adding new DenseClass-object\n","ann.add(tf.keras.layers.Dense(units=6,activation='relu')) #DenseClass will create fully connect layer of the object and automatically add the input layer in object\n","#The argument(1) \"units\" inside the Dense represents the number of Neurons in the layer, can get by experimenting with all numbers for optimum value\n","#Argumnet(2), for fully conected layer, relu is best activation function\n","#All the features would be the input-Neuron of the input-layer\n","# Add method can add any layer, specification comes inside the argumnet that is hyperparameter(parameter)\n"],"metadata":{"id":"i3bGVCs3anLv","executionInfo":{"status":"ok","timestamp":1698145655221,"user_tz":-330,"elapsed":5,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Adding the second layer"],"metadata":{"id":"YF6hBmB-xvgT"}},{"cell_type":"code","source":["#Same adding the new layer required same code and we are putting the number of neurons same\n","ann.add(tf.keras.layers.Dense(units=6,activation='relu'))"],"metadata":{"id":"swwTE23Nxzz0","executionInfo":{"status":"ok","timestamp":1698145655221,"user_tz":-330,"elapsed":5,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## Adding the output layer"],"metadata":{"id":"5aRRtgt10oCF"}},{"cell_type":"code","source":["#Hence this will also add output layer\n","#Hence we have Y as 0 or 1, then in that we require only one neuron, we have more classes like if classes are 3 we required 3 neurons, in which they have hotEncoded(if in string) and represented in 3neuron\n","#And here at the activation function would required is sigmoid function as we have binary classes and it would also provide the prob\n","ann.add(tf.keras.layers.Dense(units=1,activation='sigmoid')) #for nonBinary, activation would be softmax"],"metadata":{"id":"vr6bY1ih0qgG","executionInfo":{"status":"ok","timestamp":1698145655221,"user_tz":-330,"elapsed":4,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# **(4) Training the ANN**"],"metadata":{"id":"fHU8KoEnC3x7"}},{"cell_type":"markdown","source":["## Compiling the ANN with optimizerr,loss function and a metric"],"metadata":{"id":"YU_KmgzcC7KZ"}},{"cell_type":"code","source":["#From optimizer the model would update the weights to reduce the error-cost, so here we would use the GradientDescnt, that is stochastics Gradient Descent which would update weights after each iterations -> 'adam'\n","#For loss-function we would consider the binary_crossentropy -> for binary-classification and for non-binary-classification -> categorical_classentropy\n","#Here the metrice takes the list which gonna evaluate the ANN, but here we choose the main one\n","\n","ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"],"metadata":{"id":"R_HMml9kDH7r","executionInfo":{"status":"ok","timestamp":1698145655221,"user_tz":-330,"elapsed":4,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["##Training the model"],"metadata":{"id":"bjrpKlwULC4K"}},{"cell_type":"code","source":["ann.fit(X_train,Y_train,batch_size=32,epochs=100)\n","#Rather than compare the loss and alter weights, would do after certain batch, efficient-32, compsarison takes place as batch_learning is more efficient for training artificaial neural network\n","# 1-epoch refers counter goes from whole training dataset once, but once is not eough for neural ent for finding the correlation of features with the dependet var\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKtcHdqwLE69","executionInfo":{"status":"ok","timestamp":1698145714607,"user_tz":-330,"elapsed":59390,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"5174f0e6-d0c9-4d90-98f9-f639642b25a7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","219/219 [==============================] - 2s 3ms/step - loss: 0.6114 - accuracy: 0.6857\n","Epoch 2/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4869 - accuracy: 0.7976\n","Epoch 3/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.7977\n","Epoch 4/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4517 - accuracy: 0.7977\n","Epoch 5/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8017\n","Epoch 6/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4270 - accuracy: 0.8087\n","Epoch 7/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4125 - accuracy: 0.8243\n","Epoch 8/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8294\n","Epoch 9/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3909 - accuracy: 0.8350\n","Epoch 10/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3836 - accuracy: 0.8404\n","Epoch 11/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3773 - accuracy: 0.8411\n","Epoch 12/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3721 - accuracy: 0.8439\n","Epoch 13/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.8457\n","Epoch 14/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8456\n","Epoch 15/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3622 - accuracy: 0.8476\n","Epoch 16/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3596 - accuracy: 0.8487\n","Epoch 17/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3577 - accuracy: 0.8501\n","Epoch 18/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3562 - accuracy: 0.8499\n","Epoch 19/100\n","219/219 [==============================] - 1s 4ms/step - loss: 0.3551 - accuracy: 0.8527\n","Epoch 20/100\n","219/219 [==============================] - 1s 4ms/step - loss: 0.3540 - accuracy: 0.8507\n","Epoch 21/100\n","219/219 [==============================] - 1s 4ms/step - loss: 0.3531 - accuracy: 0.8524\n","Epoch 22/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3525 - accuracy: 0.8541\n","Epoch 23/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3513 - accuracy: 0.8531\n","Epoch 24/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8533\n","Epoch 25/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8554\n","Epoch 26/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.8551\n","Epoch 27/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8564\n","Epoch 28/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8550\n","Epoch 29/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8571\n","Epoch 30/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3464 - accuracy: 0.8579\n","Epoch 31/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8571\n","Epoch 32/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8564\n","Epoch 33/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8576\n","Epoch 34/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8586\n","Epoch 35/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3443 - accuracy: 0.8586\n","Epoch 36/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3444 - accuracy: 0.8584\n","Epoch 37/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3438 - accuracy: 0.8587\n","Epoch 38/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8599\n","Epoch 39/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8584\n","Epoch 40/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3429 - accuracy: 0.8600\n","Epoch 41/100\n","219/219 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8589\n","Epoch 42/100\n","219/219 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.8601\n","Epoch 43/100\n","219/219 [==============================] - 1s 4ms/step - loss: 0.3419 - accuracy: 0.8596\n","Epoch 44/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3420 - accuracy: 0.8596\n","Epoch 45/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8616\n","Epoch 46/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8607\n","Epoch 47/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3407 - accuracy: 0.8611\n","Epoch 48/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.8587\n","Epoch 49/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8599\n","Epoch 50/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8617\n","Epoch 51/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3399 - accuracy: 0.8624\n","Epoch 52/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3400 - accuracy: 0.8626\n","Epoch 53/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.8619\n","Epoch 54/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3396 - accuracy: 0.8614\n","Epoch 55/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3394 - accuracy: 0.8604\n","Epoch 56/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8636\n","Epoch 57/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8610\n","Epoch 58/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3389 - accuracy: 0.8630\n","Epoch 59/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8624\n","Epoch 60/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3387 - accuracy: 0.8610\n","Epoch 61/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3386 - accuracy: 0.8624\n","Epoch 62/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3387 - accuracy: 0.8629\n","Epoch 63/100\n","219/219 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8621\n","Epoch 64/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8610\n","Epoch 65/100\n","219/219 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8604\n","Epoch 66/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3383 - accuracy: 0.8617\n","Epoch 67/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8634\n","Epoch 68/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8623\n","Epoch 69/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8626\n","Epoch 70/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8637\n","Epoch 71/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3374 - accuracy: 0.8626\n","Epoch 72/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8633\n","Epoch 73/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8631\n","Epoch 74/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8629\n","Epoch 75/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8629\n","Epoch 76/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8631\n","Epoch 77/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8646\n","Epoch 78/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8637\n","Epoch 79/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.8630\n","Epoch 80/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8623\n","Epoch 81/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3360 - accuracy: 0.8634\n","Epoch 82/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8656\n","Epoch 83/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8636\n","Epoch 84/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8640\n","Epoch 85/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8629\n","Epoch 86/100\n","219/219 [==============================] - 1s 4ms/step - loss: 0.3355 - accuracy: 0.8640\n","Epoch 87/100\n","219/219 [==============================] - 1s 4ms/step - loss: 0.3353 - accuracy: 0.8629\n","Epoch 88/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8654\n","Epoch 89/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8626\n","Epoch 90/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8643\n","Epoch 91/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8650\n","Epoch 92/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8613\n","Epoch 93/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8649\n","Epoch 94/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8654\n","Epoch 95/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8666\n","Epoch 96/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8631\n","Epoch 97/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8634\n","Epoch 98/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3343 - accuracy: 0.8650\n","Epoch 99/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8667\n","Epoch 100/100\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8669\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7c055a641510>"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# **(4) Prediction and Evaluating the model**"],"metadata":{"id":"4kBm3xNwWWoL"}},{"cell_type":"code","source":["# Predicting the a test value\n","# Encode the strings\n","# We have to also scale the input as the model is train on the same scaled data and expects the input further in same scalling\n","print(ann.predict(sc_x.transform([[1.0,0.0,0.0,600,1,40,3,60000,2,1 ,1,50000]])))\n","#Hnce the sigmod activation function is at output layer so it would give the probability of leaving"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xpYWUSVWs00","executionInfo":{"status":"ok","timestamp":1698145714608,"user_tz":-330,"elapsed":16,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"8fd39307-7c01-4f2d-d2df-877ca8b96046"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 95ms/step\n","[[0.03887982]]\n"]}]},{"cell_type":"code","source":["# If you want only \"yes\" or \"no\", not wanted the probability simply add \">0.5\", 0.5 here will act like threeshold value in the sigmoid, in which value greater than 0.5 will be True -> customer will exit, else no\n","# You could change the threshold 0.5 to any of number here, as per requirement\n","print(ann.predict(sc_x.transform([[1.0,0.0,0.0,600,1,40,3,60000,2,1 ,1,50000]]))>0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"chlsY3z6iFuf","executionInfo":{"status":"ok","timestamp":1698145714608,"user_tz":-330,"elapsed":12,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"61c017f6-be73-413e-b637-9a884b7e8b1e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n","[[False]]\n"]}]},{"cell_type":"code","source":["#Example for greaqter than 0.5 -> True, exit\n","print(ann.predict(sc_x.transform([[0.0,0.0,1.0,900,1,44,3,10000,5,1 ,1,500000]])))\n","print(ann.predict(sc_x.transform([[0.0,0.0,1.0,900,1,44,3,10000,5,1 ,1,500000]]))>0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llcZXFt4hzlA","executionInfo":{"status":"ok","timestamp":1698146249349,"user_tz":-330,"elapsed":4,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"0710279f-bdab-4412-b4ae-28a8207a7927"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n","[[0.9998617]]\n","1/1 [==============================] - 0s 22ms/step\n","[[ True]]\n"]}]},{"cell_type":"code","source":["#Calculating Y_pred\n","Y_pred=(ann.predict(X_test)>0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"moN_FFdGbJdn","executionInfo":{"status":"ok","timestamp":1698146495633,"user_tz":-330,"elapsed":545,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"c4f84b5e-99ed-45af-b965-63d8ed609ffd"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["94/94 [==============================] - 0s 2ms/step\n"]}]},{"cell_type":"code","source":["np.column_stack((Y_test,Y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xoOekJRvXJ1n","executionInfo":{"status":"ok","timestamp":1698146334136,"user_tz":-330,"elapsed":778,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"7cca9688-f573-4cb1-8380-db254077c8f2"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0],\n","       [1, 0],\n","       [0, 0],\n","       ...,\n","       [0, 0],\n","       [0, 0],\n","       [1, 1]])"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["## Confusion Matrix"],"metadata":{"id":"brWiZxHHa0il"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","print(confusion_matrix(Y_test,Y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lgKdlTsqaOTb","executionInfo":{"status":"ok","timestamp":1698146588486,"user_tz":-330,"elapsed":567,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"b678a7a0-99de-498c-ceb5-8a443a392a12"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2267  112]\n"," [ 310  311]]\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","print(accuracy_score(Y_test,Y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4monEQBQbLTJ","executionInfo":{"status":"ok","timestamp":1698146625894,"user_tz":-330,"elapsed":4,"user":{"displayName":"ML BIts","userId":"06579776195890212899"}},"outputId":"50eb1ff4-e579-40d9-a90d-c55cb6943b6c"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8593333333333333\n"]}]}]}